{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mzUjMCDFVTwM"
   },
   "source": [
    "# Polynomial Ridge Regression\n",
    "\n",
    "Welcome to your third lab! You will build more Polynomial Regression with l2 regularization.\n",
    "\n",
    "You will be predicting temperature by day time.\n",
    "\n",
    "This lab is a little bit more complex than first two. You will implement this model in OOP way.\n",
    "\n",
    "**You will learn to:**\n",
    "- Build the general architecture of a learning algorithm with OOP in mind:\n",
    "    - Helper functions\n",
    "        - Generation of polynomial_features\n",
    "        - Calculation of Mean Squared Error\n",
    "        - L2 regularization\n",
    "    - Main Model Class\n",
    "        - Initializing parameters\n",
    "        - Training\n",
    "        - Prediction \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LULF64T6VTwO"
   },
   "source": [
    "## 1 - Packages ##\n",
    "\n",
    "First, let's run the cell below to import all the packages that you will need during this assignment.\n",
    "- [math](https://docs.python.org/3/library/math.html) - just math ;)\n",
    "- [numpy](www.numpy.org) is the fundamental package for scientific computing with Python.\n",
    "- [matplotlib](http://matplotlib.org) is a famous library to plot graphs in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "kzfUtoUEVTwP"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MmMjFAFkVTwS"
   },
   "source": [
    "## 2 - Overview of the Problem set ##\n",
    "\n",
    "**Problem Statement**: You are given a dataset  containing:\n",
    "    - a training set of m_train examples\n",
    "    - a test set of m_test examples\n",
    "    - each example is of shape (number of features, 1), in our case (1, 1)\n",
    "\n",
    "Let's get more familiar with the dataset. Load the data by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8xi1q04PVTwT"
   },
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "\n",
    "def load_data():\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    data = np.genfromtxt('time_temp_2016.tsv', delimiter='\\t')\n",
    "    \n",
    "    x = data[:, 0]\n",
    "    x = x.reshape((x.shape[0], 1))\n",
    "    y = data[:, 1]\n",
    "    \n",
    "    train_set_x, test_set_x, train_set_y, test_set_y = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    train_set_y = train_set_y.reshape((1, train_set_y.shape[0]))\n",
    "    test_set_y = test_set_y.reshape((1, test_set_y.shape[0]))\n",
    "    \n",
    "    return train_set_x.T, test_set_x.T, train_set_y, test_set_y, x.T\n",
    "\n",
    "train_set_x, test_set_x, train_set_y, test_set_y, full_feature_set_for_plot = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sSxdzsspVTwV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 245) (1, 245) (1, 121) (1, 121)\n"
     ]
    }
   ],
   "source": [
    "print(train_set_x.shape, train_set_y.shape, test_set_x.shape, test_set_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Un88y-VcVTwX"
   },
   "source": [
    "Many software bugs in machine learning come from having matrix/vector dimensions that don't fit. If you can keep your matrix/vector dimensions straight you will go a long way toward eliminating many bugs. \n",
    "\n",
    "**Exercise:** Find the values for:\n",
    "    - m_train (number of training examples)\n",
    "    - m_test (number of test examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SWTf0wbjVTwX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: m_train = 245\n",
      "Number of testing examples: m_test = 121\n",
      "\n",
      "train_set_x shape: (1, 245)\n",
      "train_set_y shape: (1, 245)\n",
      "test_set_x shape: (1, 121)\n",
      "test_set_y shape: (1, 121)\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ### (â‰ˆ 2 lines of code)\n",
    "m_train = train_set_x.shape[1]\n",
    "m_test = test_set_x.shape[1]\n",
    "### END CODE HERE ###\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "\n",
    "print (\"\\ntrain_set_x shape: \" + str(train_set_x.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x shape: \" + str(test_set_x.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_FyhDrZFVTwa"
   },
   "source": [
    "**Expected Output for m_train, m_test**: \n",
    "<table style=\"width:15%\">\n",
    "  <tr>\n",
    "    <td>**m_train**</td>\n",
    "    <td> 245 </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**m_test**</td>\n",
    "    <td> 121 </td> \n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Vy7c-vOVTwb"
   },
   "source": [
    "### Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "veYXpJcCVTwc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Color map\n",
    "cmap = plt.get_cmap('viridis')\n",
    "\n",
    "# Plot the results\n",
    "m1 = plt.scatter(366 * train_set_x, train_set_y, color=cmap(0.9), s=10)\n",
    "m2 = plt.scatter(366 * test_set_x, test_set_y, color=cmap(0.5), s=10)\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Temperature in Celcius')\n",
    "plt.legend((m1, m2), (\"Training data\", \"Test data\"), loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XlJmZ8Z7VTwe"
   },
   "source": [
    "## 3 - Polynomial Ridge Regression algorithm\n",
    "**Mathematical expression of the algorithm**:\n",
    "For one example $x^{(i)}$:\n",
    "\n",
    "Main trick of polynomial regression - feature combination under predefined degree.\n",
    "Let's define our $degree = 3$ and $x^{(i)} = (x_{1})$ - so that we have only one feature as in our current dataset for the sake of simplicity(later you will see generalizaed solution for any amount of features and any degree).\n",
    "\n",
    "So, having $degree = 3$ and $x^{(i)} = (x^{(i)}_{1})$ we transform our feature vector to be:\n",
    "$$x^{(i)} = (x^{0}_{1}=1, x^{1}_{1}=x_{1}, x^{2}_{1}, x^{3}_{1})$$\n",
    "\n",
    "Having more thah 1 features would cause combinations with replacements for each feature under each degree in range [0, $degree$]\n",
    "\n",
    "After that step we have regular well known process, but in this lab we will use a little trick with bias variable.\n",
    "You should already be familiar with it.\n",
    "\n",
    "Main idea is to add 1 to each training example on the first position. It gives us an ability to count our bias inside of the weights vector on the first position too. So, now our $x^{(i)}$ will look like this:\n",
    "$$x^{(i)} = (1, x^{0}_{1}=1, x^{1}_{1}=x_{1}, x^{2}_{1}, x^{3}_{1})$$\n",
    "\n",
    "So, predictor function:\n",
    "$$h^{(i)} =  w^T x^{(i)} \\tag{1}$$\n",
    "\n",
    "<b>Rigde</b> a.k.a <b>L2 Regularization</b>.\n",
    "Having really high order polynomial function we can easily overfit on our training set.\n",
    "The main technique to prevent overfitting called regularization.\n",
    "You should already be familiar with theory of l2 regularization. Our cost function will look like this:\n",
    "\n",
    "The cost is then computed by summing squared diff over all training examples:\n",
    "$$J = \\sum_{i=1}^{m}(h^{(i)} - y^{(i)})^{2} + \\lambda ||w||^2_2\\tag{2}$$\n",
    "\n",
    "Where $\\lambda$ is regularization term.\n",
    "\n",
    "Now, only gradient have to be defined.\n",
    "$$X = (x^{(1)}, x^{(2)}, ..., x^{(m-1)}, x^{(m)})$$\n",
    "$$H = (w^T X + b) = (h^{(1)}, h^{(2)}, ..., h^{(m-1)}, h^{(m)})$$\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w} = X(H-Y)^T + \\frac{1}{2}\\lambda w \\tag{5}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sm9OfaUdVTwe"
   },
   "source": [
    "### 3.1 Helper utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BCjQsPSKVTwf"
   },
   "source": [
    "In this exercise, you will lear more about custom implemenation: \n",
    "    - Generation of polynomial_features\n",
    "    - Calculation of Mean Squared Error\n",
    "    - L2 regularization\n",
    "\n",
    "Let's get more detailed look at these functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W4MJCQB8VTwg"
   },
   "source": [
    "We create function polynomial_features to transform our flat input features into features of higher degrees.\n",
    "\n",
    "As example for degree=3 and features $(x_1, x_2, x_3)$ we will get:\n",
    "\n",
    "$$((x_1, x_2, x_3),3) -> (1, x_1, x_2, x_3, x^2_1, x_1 x_2, x_1 x_3, x^2_2, x_2 x_3, x^2_3, x^3_1, x^3_2, x^3_3)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wEBlvPFPVTwh"
   },
   "outputs": [],
   "source": [
    "def polynomial_features(X, degree):\n",
    "    \n",
    "    from itertools import combinations_with_replacement \n",
    "    # combinations_with_replacement('ABC', 2) --> AA AB AC BB BC CC\n",
    "    \n",
    "    n_features, n_samples = np.shape(X)\n",
    "    \n",
    "    def index_combinations(): ## (1, 2) => [(1),(2),(1,1),(1,2),(2,2)]\n",
    "        combs = [combinations_with_replacement(range(n_features), i) for i in range(0, degree + 1)]\n",
    "        ##comb = [(),((1),(2)),((1,1),(1,2),(2,2))]\n",
    "        flat_combs = [item for sublist in combs for item in sublist]\n",
    "        ##flat_combs = [(1),(2),(1,1),(1,2),(2,2)]\n",
    "        return flat_combs\n",
    "    \n",
    "    combinations = index_combinations()\n",
    "    \n",
    "    n_output_features = len(combinations)\n",
    "    \n",
    "    X_new = np.empty((n_output_features, n_samples))\n",
    "    \n",
    "    for i, index_combs in enumerate(combinations):  \n",
    "        X_new[i, :] = np.prod(X[index_combs, :], axis=0)\n",
    "        ## if index_combs == (1,2,3) =>  X_new[:,i] = X[:,1] * X[:,2] * X[:,3] \n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qv5t6eHwVTwj"
   },
   "source": [
    "We will be using mean squared error to evaluate accuracy of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "kP8lQFc_VTwk"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: mean_squared_error\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    \"\"\" Returns the mean squared error between y_true and y_pred \n",
    "    \n",
    "    Arguments:\n",
    "    y_true -- array of true values\n",
    "    y_pred -- array of predicted values\n",
    "    \n",
    "    Returns:\n",
    "    mse -- mean squared error\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ### (â‰ˆ 1 line of code)\n",
    "    mse = (1 / y_true.shape[0]) * (y_true - y_pred).dot((y_true - y_pred).T)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "skPGXgmaVTwo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse = 1.75\n"
     ]
    }
   ],
   "source": [
    "print (\"mse = \" + str(mean_squared_error(np.array([1, 2, 3, 4]), np.array([2, 3, 4, 6]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PbTljBKTVTwp"
   },
   "source": [
    "**Expected Output**: \n",
    "<table style=\"width:30%\">\n",
    "    <tr>\n",
    "         <td>\n",
    "             **mse**\n",
    "         </td>\n",
    "         <td>\n",
    "            1.75\n",
    "         </td>  \n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-6dWE9CWVTwq"
   },
   "source": [
    "Ridge regression a.k.a L2 regularization(we will use alpha instead of lambda in the code bacause of python lambda keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "luYMVongVTwr"
   },
   "outputs": [],
   "source": [
    "# GRADED CLASS: l2_regularization\n",
    "\n",
    "class l2_regularization():\n",
    "    \"\"\" Regularization for Ridge Regression \"\"\"\n",
    "    def __init__(self, alpha):\n",
    "        \"\"\" Set alpha \"\"\"\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def __call__(self, w):\n",
    "        \"\"\" \n",
    "        Computes l2 regularization term\n",
    "        \n",
    "        Arguments:\n",
    "        w -- weights\n",
    "\n",
    "        Returns:\n",
    "        term -- 1/2 * alpha * (w, w)\n",
    "        \"\"\"\n",
    "        ### START CODE HERE ### (â‰ˆ 1 line of code)\n",
    "        term = 0.5 * self.alpha * w.dot(w.T)\n",
    "        ### END CODE HERE ###        \n",
    "        return term\n",
    "\n",
    "    def grad(self, w):\n",
    "        \"\"\" \n",
    "        Computes derivative of l2 regularization term\n",
    "        \n",
    "        Arguments:\n",
    "        w -- weights\n",
    "\n",
    "        Returns:\n",
    "        vector -- alpha * w\n",
    "        \"\"\"\n",
    "        ### START CODE HERE ### (â‰ˆ 1 line of code)\n",
    "        derivative = self.alpha * w\n",
    "        ### END CODE HERE ###      \n",
    "        \n",
    "        return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jj9oruDhVTws"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 reg. term = 7.5\n",
      "l2 grad. = [0.5 1.  1.5 2. ]\n"
     ]
    }
   ],
   "source": [
    "l2 = l2_regularization(0.5)\n",
    "print (\"l2 reg. term = \" + str(l2(np.array([1, 2, 3, 4]))))\n",
    "print (\"l2 grad. = \" + str(l2.grad(np.array([1, 2, 3, 4]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fp5H5XiKVTwv"
   },
   "source": [
    "**Expected Output**: \n",
    "\n",
    "<table style=\"width:40%\">\n",
    "    <tr>\n",
    "       <td> **l2 reg. term** </td>\n",
    "       <td> 7.5 </td>\n",
    "    </tr>\n",
    "    \n",
    "    <tr>\n",
    "       <td> **l2 grad.** </td>\n",
    "       <td> [0.5 1.  1.5 2. ] </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "itl-fbgaVTwv"
   },
   "source": [
    "### 3.2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8dQSUzNdVTwx"
   },
   "outputs": [],
   "source": [
    "# GRADED CLASS: PolynomialRidgeRegression\n",
    "\n",
    "class PolynomialRidgeRegression(object):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    degree: int\n",
    "        The degree of the polynomial that the independent variable X will be transformed to.\n",
    "    reg_factor: float\n",
    "        The factor that will determine the amount of regularization and feature\n",
    "        shrinkage. \n",
    "    n_iterations: float\n",
    "        The number of training iterations the algorithm will tune the weights for.\n",
    "    learning_rate: float\n",
    "        The step length that will be used when updating the weights.\n",
    "    \"\"\"\n",
    "    def __init__(self, degree, reg_factor, n_iterations=3000, learning_rate=0.01, print_error=False):\n",
    "        self.degree = degree\n",
    "        self.regularization = l2_regularization(alpha=reg_factor)\n",
    "        self.n_iterations = n_iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.print_error = print_error\n",
    "    \n",
    "        \n",
    "    def initialize_with_zeros(self, n_features):\n",
    "        \"\"\"\n",
    "        This function creates a vector of zeros of shape (n_features, 1)\n",
    "        \n",
    "        Arguments:\n",
    "        n_features -- amount of features\n",
    "        \"\"\"\n",
    "        ### START CODE HERE ### (â‰ˆ 1 line of code)\n",
    "        self.w = np.zeros((n_features, 1))\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        ### START CODE HERE ### \n",
    "        # Generate polynomial features (â‰ˆ 1 line of code)\n",
    "        X = polynomial_features(X, self.degree)\n",
    "\n",
    "        # Insert constant ones for bias weights (â‰ˆ 1 line of code)\n",
    "        X = np.insert(X, 0, 1., axis=0)\n",
    "        \n",
    "        # Create array\n",
    "        self.initialize_with_zeros(n_features=X.shape[0])\n",
    "\n",
    "        # Do gradient descent for n_iterations\n",
    "        for i in range(self.n_iterations):\n",
    "            # Calculate prediction (â‰ˆ 1 line of code)\n",
    "            H = self.w.T.dot(X)\n",
    "\n",
    "            # Gradient of l2 loss w.r.t w (â‰ˆ 1 line of code)\n",
    "            grad_w = (1 / X.shape[1]) * X.dot((H - Y).T) + self.regularization.grad(self.w)\n",
    "\n",
    "            # Update the weights (â‰ˆ 1 line of code)\n",
    "            self.w = self.w - self.learning_rate * grad_w\n",
    "\n",
    "            if self.print_error and i % 1000 == 0:\n",
    "                # Calculate l2 loss (â‰ˆ 1 line of code)\n",
    "                mse = mean_squared_error(Y, self.predict(X))\n",
    "                ### END CODE HERE ###\n",
    "                print (\"MSE after iteration %i: %f\" %(i, mse))\n",
    "            print(\"hm\")\n",
    "        \n",
    "            \n",
    "    def predict(self, X):\n",
    "        ### START CODE HERE ### \n",
    "        # Generate polynomial features (â‰ˆ 1 line of code)\n",
    "        print(\"hm\")\n",
    "        X = polynomial_features(X, self.degree)\n",
    "        print(\"hm\")\n",
    "        \n",
    "        # Insert constant ones for bias weights (â‰ˆ 1 line of code)\n",
    "        X = (np.ones(X.shape[1]), X)\n",
    "        \n",
    "        # Calculate prediction (â‰ˆ 1 line of code)\n",
    "        y_pred = X.dot(self.w)\n",
    "        ### END CODE HERE ### \n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sfOMOLKmVTwz"
   },
   "source": [
    "## 4 - Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DMS3RAf3VTwz"
   },
   "source": [
    "First of all we should define a maximum possible polynomial degree, learning, num_iteration and reg_factor for our model. Often reg factor is chosen with help of cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "OMp_eKnqVTw0"
   },
   "outputs": [],
   "source": [
    "poly_degree = 15\n",
    "learning_rate = 0.001\n",
    "n_iterations = 10000\n",
    "reg_factor = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3JPW8kqAVTw2"
   },
   "source": [
    "Now we can initialize our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "27_JfRk5VTw3"
   },
   "outputs": [],
   "source": [
    "model = PolynomialRidgeRegression(\n",
    "    degree=poly_degree, \n",
    "    reg_factor=reg_factor,\n",
    "    learning_rate=learning_rate,\n",
    "    n_iterations=n_iterations,\n",
    "    print_error=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u9yHZ5LDVTw4"
   },
   "source": [
    "Let's train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Kmcc8nSCVTw4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-2364e9dd4c34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-f13c745f208b>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;31m# Calculate l2 loss (â‰ˆ 1 line of code)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0;31m### END CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"MSE after iteration %i: %f\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-f13c745f208b>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# Generate polynomial features (â‰ˆ 1 line of code)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolynomial_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b514c04a67df>\u001b[0m in \u001b[0;36mpolynomial_features\u001b[0;34m(X, degree)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mflat_combs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcombinations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_combinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mn_output_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b514c04a67df>\u001b[0m in \u001b[0;36mindex_combinations\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mcombs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcombinations_with_replacement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m##comb = [(),((1),(2)),((1,1),(1,2),(2,2))]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mflat_combs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m##flat_combs = [(1),(2),(1,1),(1,2),(2,2)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mflat_combs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b514c04a67df>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mcombs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcombinations_with_replacement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m##comb = [(),((1),(2)),((1,1),(1,2),(2,2))]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mflat_combs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m##flat_combs = [(1),(2),(1,1),(1,2),(2,2)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mflat_combs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_set_x, train_set_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FcblItOfVTw6"
   },
   "source": [
    "**Expected Output**: \n",
    "\n",
    "<table style=\"width:40%\"> \n",
    "    <tr>\n",
    "        <td> **MSE after iteration 0 **  </td> \n",
    "        <td> 127.482367 </td>\n",
    "    </tr>\n",
    "      <tr>\n",
    "        <td> <center> $\\vdots$ </center> </td> \n",
    "        <td> <center> $\\vdots$ </center> </td> \n",
    "    </tr>  \n",
    "    <tr>\n",
    "        <td> **MSE after iteration 9000**  </td> \n",
    "        <td> 12.618504 </td>\n",
    "    </tr>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Th6FczyBVTw7"
   },
   "source": [
    "## 4 - Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8gSf84zmVTw8"
   },
   "outputs": [],
   "source": [
    "y_predictions = model.predict(test_set_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gb8W2Z-JVTw-"
   },
   "source": [
    "Let's calculate mean squred error(MSE):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NRTQXtDKVTw-"
   },
   "outputs": [],
   "source": [
    "mse = mean_squared_error(test_set_y, y_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6eImX7c5VTxA"
   },
   "outputs": [],
   "source": [
    "print (\"Mean squared error on test set: %s (given by reg. factor: %s)\" % (mse, reg_factor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVehJnrsVTxB"
   },
   "source": [
    "**Expected Output**: \n",
    "\n",
    "<table style=\"width:40%\"> \n",
    "    <tr>\n",
    "        <td> **MSE **  </td> \n",
    "        <td> 11.01910317263094 </td>\n",
    "    </tr>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ubgGmdSkVTxC"
   },
   "source": [
    "## 5 - Results visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "s5REMxqxVTxC"
   },
   "outputs": [],
   "source": [
    "# Color map\n",
    "cmap = plt.get_cmap('viridis')\n",
    "\n",
    "# Predict for all points in set\n",
    "y_val = model.predict(full_feature_set_for_plot)\n",
    "\n",
    "# Plot the results\n",
    "m1 = plt.scatter(366 * train_set_x, train_set_y, color=cmap(0.9), s=10)\n",
    "m2 = plt.scatter(366 * test_set_x, test_set_y, color=cmap(0.5), s=10)\n",
    "plt.plot(366 * full_feature_set_for_plot.T, y_val.T, color='black', linewidth=2, label=\"Prediction\")\n",
    "plt.suptitle(\"Polynomial Ridge Regression\")\n",
    "plt.title(\"MSE: %.2f\" % mse, fontsize=10)\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Temperature in Celcius')\n",
    "plt.legend((m1, m2), (\"Training data\", \"Test data\"), loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Polynomial_Ridge_Regression.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
